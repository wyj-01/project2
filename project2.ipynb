{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project2 LeNet-TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取数据\n",
    "首先利用TensorFlow中的pre-loaded读取手写体的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-566519a95339>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From E:\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From E:\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From E:\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From E:\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "\n",
      "Image Shape: (28, 28, 1)\n",
      "\n",
      "Training Set:   55000 samples\n",
      "Validation Set: 5000 samples\n",
      "Test Set:       10000 samples\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", reshape=False)\n",
    "X_train, y_train           = mnist.train.images, mnist.train.labels\n",
    "X_validation, y_validation = mnist.validation.images, mnist.validation.labels\n",
    "X_test, y_test             = mnist.test.images, mnist.test.labels\n",
    "\n",
    "assert(len(X_train) == len(y_train))\n",
    "assert(len(X_validation) == len(y_validation))\n",
    "assert(len(X_test) == len(y_test))\n",
    "\n",
    "print()\n",
    "print(\"Image Shape: {}\".format(X_train[0].shape))\n",
    "print()\n",
    "print(\"Training Set:   {} samples\".format(len(X_train)))\n",
    "print(\"Validation Set: {} samples\".format(len(X_validation)))\n",
    "print(\"Test Set:       {} samples\".format(len(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据初步处理\n",
    "由于TensorFlow读取到的图像是28x28x1的图像，而LeNet只能接受32x32xC的图像，所以为了能使LeNet可以工作，要对读取到的图像进行处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Image Shape: (32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Pad images with 0s\n",
    "X_train      = np.pad(X_train, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "X_validation = np.pad(X_validation, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "X_test       = np.pad(X_test, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "    \n",
    "print(\"Updated Image Shape: {}\".format(X_train[0].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "图像处理完成后，随机读取一个图像进行展示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFsAAABZCAYAAABR/liSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAABHNJREFUeJztnD2IXFUUx39/o1axiIgSNKiIfQSxsdg3iCA2UUExhSgIaxPQTrHZ2S6F2gobDFgIIiiYTix2FmwkawhqXNQgoqtLRFSMNqIei3lvGWffzLydO+/M2zfnB8P7nHvP/OfMuR/vzJWZEfhwzbwNWCRCbEdCbEdCbEdCbEdCbEdCbEeSxJb0kKQvJV2W9NKsjGormnZQI+kQ8BXwILANnAdOmtkXszOvXVyb8N77gMtm9g2ApLeBE8BIsSW1drhqZpp0T0oYuRX4fuB4Oz/3PyQtS9qUtJlQVytI8eyyb3KP55rZGrAG7fbsKqR49jZwbOD4NuDHNHPaTYrY54G7Jd0p6XrgSeDcbMxqJ1OHETP7W9Ip4APgEHDWzC7NzLIWMnXXb6rKWhyz6+6NBPskxHYkxHYkxHYkxHYkxHYkxHYkxHYkxHYkxHYkZYq1NrIsA2BlZWX3uNfrAbCxsZFUdlFmGZ1OZ7eeOgjPdqTRnl1sR52ro97w7JbQyCnWwnvX19frNGcP0sRZ0pFUmWJtZBgpfsrFdlwD2e1297y/2+3uKWPw2nAjubq6mmpyJSKMONJIzy4ovDjLst39Mk8epso98yA825FGNpAFhYcOxtiURgyg7POmlpmXezAbyDooCy119qnLiDDiyMJ4dtmcSOo8y34Jz3ak0Z5dxNmlpaVaym9czJZ0TNK6pC1JlyQ9n5+/UdKHkr7Ot0fqN/dgM7HrJ+kocNTMLki6AfgEeAR4BvjFzE7nf/E4YmYvTihrbulndXX5BspP7/qZ2Q6wk+9flbRFP+n9BJDlt70J9ICxYs+DJnT5CvYVsyXdAdwDfAzckn8RmNmOpJtHvGcZWE4zsyWYWaUXcJh+CHksP/5t6PqvFcowr1eWZZZlmZVRXJtlfVU0rNT1k3Qd8C7wlpm9l5++ksfzIq7/VKWsRWZiGFG/FXkD2DKz1wYunQOeBk7n2/drsXBKRj0+6/V6jY7Z9wNPAZ9Jupife5m+yO9Iehb4Dni8HhPbQ5XeyEeU/zMM4IHZmjM7Rg2EvIfogzR6BJlCnU/hpyXmRhxppdjxWCxYPLHn6fWNfgY5LWWfqehbdzqduuqM/0E2idZ2/YbxynoaR3i2I6307E6ns/uAtxgxzms+ZJDwbEda2RuZB9EbaRghtiPeDeTPwJ/5tuncRHU7b69yk2vMBpC0aWb3ulY6BXXYGWHEkRDbkXmIvTaHOqdh5na6x+xFJsKII25iN3mt7TGZul1JP0i6mL8eTqrHI4w0fa3tMZm6TwB/mNkrs6jHy7N319o2s7+AYq3tRmBmO2Z2Id+/ChSZujPFS+xKa203gaFMXYBTkj6VdDY14d9L7Eprbc8bSYfpJ5C+YGa/A68DdwHH6eeov5pSvpfYjV9ruyxT18yumNk/ZvYvcIZ+OJwaL7Ebvdb2qEzdIiU651Hg85R6XGb9DsBa26MydU9KOk4/5H0LPJdSSYwgHYkRpCMhtiMhtiMhtiMhtiMhtiMhtiMhtiP/AQtfL3A7ujNVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "index = random.randint(0, len(X_train))\n",
    "image = X_train[index].squeeze()\n",
    "\n",
    "plt.figure(figsize=(1,1))\n",
    "plt.imshow(image, cmap=\"gray\")\n",
    "print(y_train[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 区分训练集\n",
    "对处理完成的数据进行洗牌，区分出训练集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.layers import flatten\n",
    "def LeNet(x):    \n",
    "    mu = 0\n",
    "    sigma = 0.1\n",
    "    #第一层卷积，输入为32x32x1，输出为28x28x6，卷积核大小为5x5，输出6个特征平面.\n",
    "    conv1_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 1, 6), mean = mu, stddev = sigma))\n",
    "    conv1_b = tf.Variable(tf.zeros(6))\n",
    "    conv1   = tf.nn.conv2d(x, conv1_W, strides=[1, 1, 1, 1], padding='VALID') + conv1_b\n",
    "    conv1 = tf.nn.relu(conv1)\n",
    "    #池化，输入为28x28x6，输出为14x14x6.\n",
    "    conv1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "    #第一层卷积，输入为14x14x6，输出为10x10x16，卷积核大小为5x5，输出16个特征平面.\n",
    "    conv2_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 6, 16), mean = mu, stddev = sigma))\n",
    "    conv2_b = tf.Variable(tf.zeros(16))\n",
    "    conv2   = tf.nn.conv2d(conv1, conv2_W, strides=[1, 1, 1, 1], padding='VALID') + conv2_b\n",
    "    conv2 = tf.nn.relu(conv2)\n",
    "    #池化，输入为10x10x16，输出为5x5x16.\n",
    "    conv2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "    #归并，输入为5x5x16，输出为400.\n",
    "    fc0   = flatten(conv2)\n",
    "    \n",
    "    #全连接，Input = 400. Output = 120.\n",
    "    fc1_W = tf.Variable(tf.truncated_normal(shape=(400, 120), mean = mu, stddev = sigma))\n",
    "    fc1_b = tf.Variable(tf.zeros(120))\n",
    "    fc1   = tf.matmul(fc0, fc1_W) + fc1_b\n",
    "    fc1   = tf.nn.relu(fc1)\n",
    "\n",
    "    #全连接，Input = 120. Output = 84.\n",
    "    fc2_W  = tf.Variable(tf.truncated_normal(shape=(120, 84), mean = mu, stddev = sigma))\n",
    "    fc2_b  = tf.Variable(tf.zeros(84))\n",
    "    fc2    = tf.matmul(fc1, fc2_W) + fc2_b\n",
    "    fc2    = tf.nn.relu(fc2)\n",
    "\n",
    "    #全连接，Input = 84. Output = 10.\n",
    "    fc3_W  = tf.Variable(tf.truncated_normal(shape=(84, 10), mean = mu, stddev = sigma))\n",
    "    fc3_b  = tf.Variable(tf.zeros(10))\n",
    "    logits = tf.matmul(fc2, fc3_W) + fc3_b\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, (None, 32, 32, 1))\n",
    "y = tf.placeholder(tf.int32, (None))\n",
    "one_hot_y = tf.one_hot(y, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x0000028FB30D9AC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x0000028FB30D9AC8>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x0000028FB30D9AC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x0000028FB30D9AC8>>: AttributeError: module 'gast' has no attribute 'Index'\n"
     ]
    }
   ],
   "source": [
    "rate = 0.001\n",
    "\n",
    "logits = LeNet(x)\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=one_hot_y, logits=logits)\n",
    "loss_operation = tf.reduce_mean(cross_entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = rate)\n",
    "training_operation = optimizer.minimize(loss_operation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "def evaluate(X_data, y_data):\n",
    "    num_examples = len(X_data)\n",
    "    total_accuracy = 0\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0, num_examples, BATCH_SIZE):\n",
    "        batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
    "        accuracy = sess.run(accuracy_operation, feed_dict={x: batch_x, y: batch_y})\n",
    "        total_accuracy += (accuracy * len(batch_x))\n",
    "    return total_accuracy / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "\n",
      "EPOCH 1 ...\n",
      "Validation Accuracy = 0.962\n",
      "\n",
      "EPOCH 2 ...\n",
      "Validation Accuracy = 0.980\n",
      "\n",
      "EPOCH 3 ...\n",
      "Validation Accuracy = 0.985\n",
      "\n",
      "EPOCH 4 ...\n",
      "Validation Accuracy = 0.984\n",
      "\n",
      "EPOCH 5 ...\n",
      "Validation Accuracy = 0.986\n",
      "\n",
      "EPOCH 6 ...\n",
      "Validation Accuracy = 0.989\n",
      "\n",
      "EPOCH 7 ...\n",
      "Validation Accuracy = 0.989\n",
      "\n",
      "EPOCH 8 ...\n",
      "Validation Accuracy = 0.990\n",
      "\n",
      "EPOCH 9 ...\n",
      "Validation Accuracy = 0.990\n",
      "\n",
      "EPOCH 10 ...\n",
      "Validation Accuracy = 0.989\n",
      "\n",
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    num_examples = len(X_train)\n",
    "    \n",
    "    print(\"Training...\")\n",
    "    print()\n",
    "    for i in range(EPOCHS):\n",
    "        X_train, y_train = shuffle(X_train, y_train)\n",
    "        for offset in range(0, num_examples, BATCH_SIZE):\n",
    "            end = offset + BATCH_SIZE\n",
    "            batch_x, batch_y = X_train[offset:end], y_train[offset:end]\n",
    "            sess.run(training_operation, feed_dict={x: batch_x, y: batch_y})\n",
    "            \n",
    "        validation_accuracy = evaluate(X_validation, y_validation)\n",
    "        print(\"EPOCH {} ...\".format(i+1))\n",
    "        print(\"Validation Accuracy = {:.3f}\".format(validation_accuracy))\n",
    "        print()\n",
    "        \n",
    "    saver.save(sess, './lenet')\n",
    "    print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from .\\lenet\n",
      "Test Accuracy = 0.990\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
    "\n",
    "    test_accuracy = evaluate(X_test, y_test)\n",
    "    print(\"Test Accuracy = {:.3f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.layers import flatten\n",
    "\n",
    "def LeNet(x):    \n",
    "    # Arguments used for tf.truncated_normal, randomly defines variables for the weights and biases for each layer\n",
    "    mu = 0\n",
    "    sigma = 0.1\n",
    "    \n",
    "    #第一层卷积，输入为32x32x1，输出为30x30x8，卷积核大小为3x3，输出8个特征平面.\n",
    "    conv1_W = tf.Variable(tf.truncated_normal(shape=(3, 3, 1, 8), mean = mu, stddev = sigma))\n",
    "    conv1_b = tf.Variable(tf.zeros(8))\n",
    "    conv1   = tf.nn.conv2d(x, conv1_W, strides=[1, 1, 1, 1], padding='VALID') + conv1_b\n",
    "    conv1 = tf.nn.relu(conv1)\n",
    "    #池化，输入为30x30x8，输出为15x15x8.\n",
    "    conv1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "    #第二层卷积，输入为15x15x8，输出为12x12x20，卷积核大小为3x3，输出20个特征平面.\n",
    "    conv2_W = tf.Variable(tf.truncated_normal(shape=(3, 3, 8, 20), mean = mu, stddev = sigma))\n",
    "    conv2_b = tf.Variable(tf.zeros(20))\n",
    "    conv2   = tf.nn.conv2d(conv1, conv2_W, strides=[1, 1, 1, 1], padding='VALID') + conv2_b\n",
    "    conv2 = tf.nn.relu(conv2)\n",
    "    #池化，输入为12x12x20，输出为4x4x20.\n",
    "    conv2 = tf.nn.max_pool(conv2, ksize=[1, 3, 3, 1], strides=[1, 3, 3, 1], padding='VALID')\n",
    "\n",
    "    #归并，输入为4x4x20，输出为320.\n",
    "    fc0   = flatten(conv2)\n",
    "    \n",
    "    # SOLUTION: Layer 3: Fully Connected. Input = 320. Output = 120.\n",
    "    fc1_W = tf.Variable(tf.truncated_normal(shape=(320, 120), mean = mu, stddev = sigma))\n",
    "    fc1_b = tf.Variable(tf.zeros(120))\n",
    "    fc1   = tf.matmul(fc0, fc1_W) + fc1_b\n",
    "    \n",
    "    # SOLUTION: Activation.\n",
    "    fc1    = tf.nn.relu(fc1)\n",
    "\n",
    "    # SOLUTION: Layer 4: Fully Connected. Input = 120. Output = 84.\n",
    "    fc2_W  = tf.Variable(tf.truncated_normal(shape=(120, 84), mean = mu, stddev = sigma))\n",
    "    fc2_b  = tf.Variable(tf.zeros(84))\n",
    "    fc2    = tf.matmul(fc1, fc2_W) + fc2_b\n",
    "    \n",
    "    # SOLUTION: Activation.\n",
    "    fc2    = tf.nn.relu(fc2)\n",
    "\n",
    "    # SOLUTION: Layer 5: Fully Connected. Input = 84. Output = 10.\n",
    "    fc3_W  = tf.Variable(tf.truncated_normal(shape=(84, 10), mean = mu, stddev = sigma))\n",
    "    fc3_b  = tf.Variable(tf.zeros(10))\n",
    "    logits = tf.matmul(fc2, fc3_W) + fc3_b\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, (None, 32, 32, 1))\n",
    "y = tf.placeholder(tf.int32, (None))\n",
    "one_hot_y = tf.one_hot(y, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x0000028FB38109B0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x0000028FB38109B0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x0000028FB38109B0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x0000028FB38109B0>>: AttributeError: module 'gast' has no attribute 'Index'\n"
     ]
    }
   ],
   "source": [
    "rate = 0.001\n",
    "\n",
    "logits = LeNet(x)\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=one_hot_y, logits=logits)\n",
    "loss_operation = tf.reduce_mean(cross_entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = rate)\n",
    "training_operation = optimizer.minimize(loss_operation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "def evaluate(X_data, y_data):\n",
    "    num_examples = len(X_data)\n",
    "    total_accuracy = 0\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0, num_examples, BATCH_SIZE):\n",
    "        batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
    "        accuracy = sess.run(accuracy_operation, feed_dict={x: batch_x, y: batch_y})\n",
    "        total_accuracy += (accuracy * len(batch_x))\n",
    "    return total_accuracy / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "\n",
      "EPOCH 1 ...\n",
      "Validation Accuracy = 0.963\n",
      "\n",
      "EPOCH 2 ...\n",
      "Validation Accuracy = 0.974\n",
      "\n",
      "EPOCH 3 ...\n",
      "Validation Accuracy = 0.985\n",
      "\n",
      "EPOCH 4 ...\n",
      "Validation Accuracy = 0.983\n",
      "\n",
      "EPOCH 5 ...\n",
      "Validation Accuracy = 0.980\n",
      "\n",
      "EPOCH 6 ...\n",
      "Validation Accuracy = 0.988\n",
      "\n",
      "EPOCH 7 ...\n",
      "Validation Accuracy = 0.989\n",
      "\n",
      "EPOCH 8 ...\n",
      "Validation Accuracy = 0.988\n",
      "\n",
      "EPOCH 9 ...\n",
      "Validation Accuracy = 0.990\n",
      "\n",
      "EPOCH 10 ...\n",
      "Validation Accuracy = 0.990\n",
      "\n",
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    num_examples = len(X_train)\n",
    "    \n",
    "    print(\"Training...\")\n",
    "    print()\n",
    "    for i in range(EPOCHS):\n",
    "        X_train, y_train = shuffle(X_train, y_train)\n",
    "        for offset in range(0, num_examples, BATCH_SIZE):\n",
    "            end = offset + BATCH_SIZE\n",
    "            batch_x, batch_y = X_train[offset:end], y_train[offset:end]\n",
    "            sess.run(training_operation, feed_dict={x: batch_x, y: batch_y})\n",
    "            \n",
    "        validation_accuracy = evaluate(X_validation, y_validation)\n",
    "        print(\"EPOCH {} ...\".format(i+1))\n",
    "        print(\"Validation Accuracy = {:.3f}\".format(validation_accuracy))\n",
    "        print()\n",
    "        \n",
    "    saver.save(sess, './lenet')\n",
    "    print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from .\\lenet\n",
      "Test Accuracy = 0.988\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
    "\n",
    "    test_accuracy = evaluate(X_test, y_test)\n",
    "    print(\"Test Accuracy = {:.3f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x0000028FB6A32400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x0000028FB6A32400>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x0000028FB6A32400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x0000028FB6A32400>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "Training...\n",
      "\n",
      "EPOCH 1 ...\n",
      "Validation Accuracy = 0.966\n",
      "\n",
      "EPOCH 2 ...\n",
      "Validation Accuracy = 0.977\n",
      "\n",
      "EPOCH 3 ...\n",
      "Validation Accuracy = 0.982\n",
      "\n",
      "EPOCH 4 ...\n",
      "Validation Accuracy = 0.982\n",
      "\n",
      "EPOCH 5 ...\n",
      "Validation Accuracy = 0.984\n",
      "\n",
      "EPOCH 6 ...\n",
      "Validation Accuracy = 0.986\n",
      "\n",
      "EPOCH 7 ...\n",
      "Validation Accuracy = 0.990\n",
      "\n",
      "EPOCH 8 ...\n",
      "Validation Accuracy = 0.985\n",
      "\n",
      "EPOCH 9 ...\n",
      "Validation Accuracy = 0.988\n",
      "\n",
      "EPOCH 10 ...\n",
      "Validation Accuracy = 0.987\n",
      "\n",
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.contrib.layers import flatten\n",
    "def LeNet(x):    \n",
    "    mu = 0\n",
    "    sigma = 0.1\n",
    "    #第一层卷积，输入为32x32x1，输出为24x24x6，卷积核大小为9x9，输出6个特征平面.\n",
    "    conv1_W = tf.Variable(tf.truncated_normal(shape=(9, 9, 1, 6), mean = mu, stddev = sigma))\n",
    "    conv1_b = tf.Variable(tf.zeros(6))\n",
    "    conv1   = tf.nn.conv2d(x, conv1_W, strides=[1, 1, 1, 1], padding='VALID') + conv1_b\n",
    "    conv1 = tf.nn.relu(conv1)\n",
    "    #池化，输入为24x24x6，输出为12x12x6.\n",
    "    conv1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "    #第一层卷积，输入为12x12x6，输出为8x8x16，卷积核大小为5x5，输出16个特征平面.\n",
    "    conv2_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 6, 16), mean = mu, stddev = sigma))\n",
    "    conv2_b = tf.Variable(tf.zeros(16))\n",
    "    conv2   = tf.nn.conv2d(conv1, conv2_W, strides=[1, 1, 1, 1], padding='VALID') + conv2_b\n",
    "    conv2 = tf.nn.relu(conv2)\n",
    "\n",
    "    #池化，输入为8x8x16，输出为4x4x16.\n",
    "    conv2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "    #归并，输入为4x4x16，输出为256.\n",
    "    fc0   = flatten(conv2)\n",
    "    \n",
    "    #全连接，Input = 256. Output = 120.\n",
    "    fc1_W = tf.Variable(tf.truncated_normal(shape=(256, 120), mean = mu, stddev = sigma))\n",
    "    fc1_b = tf.Variable(tf.zeros(120))\n",
    "    fc1   = tf.matmul(fc0, fc1_W) + fc1_b\n",
    "    fc1   = tf.nn.relu(fc1)\n",
    "\n",
    "    #全连接，Input = 120. Output = 84.\n",
    "    fc2_W  = tf.Variable(tf.truncated_normal(shape=(120, 84), mean = mu, stddev = sigma))\n",
    "    fc2_b  = tf.Variable(tf.zeros(84))\n",
    "    fc2    = tf.matmul(fc1, fc2_W) + fc2_b\n",
    "    fc2    = tf.nn.relu(fc2)\n",
    "\n",
    "    #全连接，Input = 84. Output = 10.\n",
    "    fc3_W  = tf.Variable(tf.truncated_normal(shape=(84, 10), mean = mu, stddev = sigma))\n",
    "    fc3_b  = tf.Variable(tf.zeros(10))\n",
    "    logits = tf.matmul(fc2, fc3_W) + fc3_b\n",
    "    \n",
    "    return logits\n",
    "\n",
    "x = tf.placeholder(tf.float32, (None, 32, 32, 1))\n",
    "y = tf.placeholder(tf.int32, (None))\n",
    "one_hot_y = tf.one_hot(y, 10)\n",
    "\n",
    "rate = 0.001\n",
    "\n",
    "logits = LeNet(x)\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=one_hot_y, logits=logits)\n",
    "loss_operation = tf.reduce_mean(cross_entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = rate)\n",
    "training_operation = optimizer.minimize(loss_operation)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "def evaluate(X_data, y_data):\n",
    "    num_examples = len(X_data)\n",
    "    total_accuracy = 0\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0, num_examples, BATCH_SIZE):\n",
    "        batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
    "        accuracy = sess.run(accuracy_operation, feed_dict={x: batch_x, y: batch_y})\n",
    "        total_accuracy += (accuracy * len(batch_x))\n",
    "    return total_accuracy / num_examples\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    num_examples = len(X_train)\n",
    "    \n",
    "    print(\"Training...\")\n",
    "    print()\n",
    "    for i in range(EPOCHS):\n",
    "        X_train, y_train = shuffle(X_train, y_train)\n",
    "        for offset in range(0, num_examples, BATCH_SIZE):\n",
    "            end = offset + BATCH_SIZE\n",
    "            batch_x, batch_y = X_train[offset:end], y_train[offset:end]\n",
    "            sess.run(training_operation, feed_dict={x: batch_x, y: batch_y})\n",
    "            \n",
    "        validation_accuracy = evaluate(X_validation, y_validation)\n",
    "        print(\"EPOCH {} ...\".format(i+1))\n",
    "        print(\"Validation Accuracy = {:.3f}\".format(validation_accuracy))\n",
    "        print()\n",
    "        \n",
    "    saver.save(sess, './lenet')\n",
    "    print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from .\\lenet\n",
      "Test Accuracy = 0.987\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
    "\n",
    "    test_accuracy = evaluate(X_test, y_test)\n",
    "    print(\"Test Accuracy = {:.3f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project2 LeNet-Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "E:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "E:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "E:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "E:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "E:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "E:\\Anaconda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "E:\\Anaconda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "E:\\Anaconda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "E:\\Anaconda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "E:\\Anaconda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "E:\\Anaconda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 24, 24, 6)         156       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 12, 12, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 8, 8, 16)          2416      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 4, 4, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 120)               30840     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 44,426\n",
      "Trainable params: 44,426\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 28s 470us/sample - loss: 0.1494 - acc: 0.9540 - val_loss: 0.0684 - val_acc: 0.9780\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 27s 449us/sample - loss: 0.0702 - acc: 0.9784 - val_loss: 0.0715 - val_acc: 0.9773\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 24s 408us/sample - loss: 0.0533 - acc: 0.9838 - val_loss: 0.0604 - val_acc: 0.9813\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 27s 454us/sample - loss: 0.0436 - acc: 0.9860 - val_loss: 0.0582 - val_acc: 0.9827\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 26s 431us/sample - loss: 0.0378 - acc: 0.9884 - val_loss: 0.0601 - val_acc: 0.9819\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 26s 432us/sample - loss: 0.0356 - acc: 0.9883 - val_loss: 0.0600 - val_acc: 0.9824\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 26s 436us/sample - loss: 0.0306 - acc: 0.9903 - val_loss: 0.0559 - val_acc: 0.9850\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 26s 442us/sample - loss: 0.0253 - acc: 0.9917 - val_loss: 0.0640 - val_acc: 0.9839\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 26s 441us/sample - loss: 0.0271 - acc: 0.9913 - val_loss: 0.0899 - val_acc: 0.9765\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 26s 439us/sample - loss: 0.0264 - acc: 0.9912 - val_loss: 0.0648 - val_acc: 0.9824\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "# 使用keras内置的mnist数据集\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# 处理一下数据\n",
    "training_images = training_images.reshape(-1, 28, 28, 1)\n",
    "test_images = test_images.reshape(-1, 28, 28, 1)\n",
    "\n",
    "training_images, test_images = training_images / 255.0, test_images / 255.0\n",
    "# print(test_images) # one-hot code\n",
    "\n",
    "# 定义模型lenet\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(6, (5,5), activation='tanh', input_shape=(28,28,1)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(16, (5,5), activation='tanh'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(120, activation='tanh'),\n",
    "    tf.keras.layers.Dense(84, activation='tanh'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# keras.optimizers.SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False)\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "             optimizer=SGD(lr=0.05, decay=1e-6, momentum=0.9, nesterov=True), \n",
    "             metrics=['acc'])\n",
    "\n",
    "# fit(x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, validation_freq=1)\n",
    "history = model.fit(training_images, training_labels, batch_size=32, epochs=10, verbose=1, shuffle=True, validation_data=(test_images, test_labels))\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, loss, 'r', label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss, 'b', label=\"Validation loss\")\n",
    "plt.title(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, acc, 'r', label=\"Training acc\")\n",
    "plt.plot(epochs, val_acc, 'b', label=\"Validation acc\")\n",
    "plt.title(\"Acc\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 6)         60        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 9, 9, 16)          2416      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 120)               30840     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 44,330\n",
      "Trainable params: 44,330\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 25s 409us/sample - loss: 0.1521 - acc: 0.9526 - val_loss: 0.0951 - val_acc: 0.9712\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 24s 398us/sample - loss: 0.0731 - acc: 0.9780 - val_loss: 0.0595 - val_acc: 0.9811\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 24s 398us/sample - loss: 0.0544 - acc: 0.9835 - val_loss: 0.0673 - val_acc: 0.9798\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 24s 400us/sample - loss: 0.0469 - acc: 0.9851 - val_loss: 0.0564 - val_acc: 0.9824\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 24s 399us/sample - loss: 0.0406 - acc: 0.9872 - val_loss: 0.0632 - val_acc: 0.9823\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 25s 413us/sample - loss: 0.0351 - acc: 0.9889 - val_loss: 0.0594 - val_acc: 0.9834\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 27s 444us/sample - loss: 0.0324 - acc: 0.9898 - val_loss: 0.0662 - val_acc: 0.9832\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 24s 401us/sample - loss: 0.0330 - acc: 0.9892 - val_loss: 0.0614 - val_acc: 0.9835\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 24s 401us/sample - loss: 0.0296 - acc: 0.9905 - val_loss: 0.0593 - val_acc: 0.9837\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 24s 401us/sample - loss: 0.0271 - acc: 0.9911 - val_loss: 0.0771 - val_acc: 0.9812\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "# 使用keras内置的mnist数据集\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# 处理一下数据\n",
    "training_images = training_images.reshape(-1, 28, 28, 1)\n",
    "test_images = test_images.reshape(-1, 28, 28, 1)\n",
    "\n",
    "training_images, test_images = training_images / 255.0, test_images / 255.0\n",
    "# print(test_images) # one-hot code\n",
    "\n",
    "# 定义模型lenet\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(6, (3,3), activation='tanh', input_shape=(28,28,1)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(16, (5,5), activation='tanh'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(120, activation='tanh'),\n",
    "    tf.keras.layers.Dense(84, activation='tanh'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# keras.optimizers.SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False)\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "             optimizer=SGD(lr=0.05, decay=1e-6, momentum=0.9, nesterov=True), \n",
    "             metrics=['acc'])\n",
    "\n",
    "# fit(x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, validation_freq=1)\n",
    "history = model.fit(training_images, training_labels, batch_size=32, epochs=10, verbose=1, shuffle=True, validation_data=(test_images, test_labels))\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, loss, 'r', label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss, 'b', label=\"Validation loss\")\n",
    "plt.title(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, acc, 'r', label=\"Training acc\")\n",
    "plt.plot(epochs, val_acc, 'b', label=\"Validation acc\")\n",
    "plt.title(\"Acc\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
